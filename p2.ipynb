{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "# Quick value count calculator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#a function for read data set\n",
    "df = pd.read_csv(\"/Users/najmeh/Desktop/master/Ml/projet/glass.csv\")\n",
    "features = df.columns[:-1].tolist()\n",
    "print(df.shape)\n",
    "df.head(2)\n",
    "\n",
    "#discrete data\n",
    "import pandas as pd\n",
    "def discretization(self):\n",
    "        exc = pd.ExcelFile(self.file_location).parse(self.sheet)\n",
    "        exc['RI']=pd.cut(exc['RI'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['Na']=pd.cut(exc['Na'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['Mg']=pd.cut(exc['Mg'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['Al']=pd.cut(exc['Al'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['Si']=pd.cut(exc['Si'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['K']=pd.cut(exc['K'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['Ca']=pd.cut(exc['Ca'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['Ba']=pd.cut(exc['Ba'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['Fe']=pd.cut(exc['Fe'],3,labels = ['low', 'Normal','High'])\n",
    "        exc['Type']=pd.cut(exc['Type'],7,labels = ['building_windows_float_processed', 'building_windows_non_float_processed','vehicle_windows_float_processed','vehicle_windows_non_float_processed ', 'containers','tableware','headlamps'])\n",
    "        exc.to_excel(self.save_file_location,index=False)\n",
    "\n",
    "#transform data six class 1,2,3,5,6,7 in target\n",
    "pd.cut(df['Type'], bins=6).value_counts()\n",
    "df['Type'].plot(kind='hist')\n",
    "\n",
    "#spilit data to two group(training and test)\n",
    "\n",
    "training_data = df.sample(frac=0.7, random_state=25)\n",
    "testing_data = df.drop(training_data.index)\n",
    "\n",
    "print(f\"number of training examples: {training_data.shape[0]}\")\n",
    "print(f\"number of testing examples: {testing_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate entropy\n",
    "entropy_node = 0  \n",
    "#Unique objects - 1,2,3,5,6,,7\n",
    "#here attribute = 'Type'\n",
    "values = df.Type.unique()  \n",
    "for value in values:\n",
    "    fraction = df.Type.value_counts()[value]/len(df.Type)  \n",
    "    entropy_node += -fraction*np.log2(fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show us = entropy of the whole dataset\n",
    "entropy_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent(df,attribute):\n",
    "    target_variables = df.Type.unique()  #This gives all 'Yes'=1 and 'No'=0\n",
    "    variables = df[attribute].unique()    \n",
    "\n",
    "\n",
    "    entropy_attribute = 0\n",
    "    for variable in variables:\n",
    "        entropy_each_feature = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df.Type ==target_variable]) #numerator\n",
    "            den = len(df[attribute][df[attribute]==variable])  \n",
    "            fraction = num/(den+eps)  #pi\n",
    "            entropy_each_feature += -fraction*log(fraction+eps) \n",
    "        fraction2 = den/len(df)\n",
    "        entropy_attribute += -fraction2*entropy_each_feature   #Sums up all the entropy ETaste\n",
    "\n",
    "    return(abs(entropy_attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find entropy of all attribute\n",
    "a_entropy = {k:ent(df,k) for k in df.keys()[:-1]}\n",
    "a_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function for calculate information gain\n",
    "def ig(e_dataset,e_attr):\n",
    "    return(e_dataset-e_attr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IG = {k:ig(entropy_node,a_entropy[k]) for k in a_entropy}\n",
    "t22=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy(df):\n",
    "    Class = df.keys()[-1]  \n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "    return entropy\n",
    "  \n",
    "  \n",
    "def find_entropy_attribute(df,attribute):\n",
    "#To make the code generic, changing target variable class name\n",
    "  Class = df.keys()[-1]  \n",
    "  #This gives all 'Yes' and 'No'\n",
    "  target_variables = df[Class].unique()  \n",
    "  #This gives different features in that attribute (like '0','y' in sex)\n",
    "  variables = df[attribute].unique()    \n",
    "  entropy2 = 0\n",
    "  for variable in variables:\n",
    "      entropy = 0\n",
    "      for target_variable in target_variables:\n",
    "          num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "          den = len(df[attribute][df[attribute]==variable])\n",
    "          fraction = num/(den+eps)\n",
    "          entropy += -fraction*log(fraction+eps)\n",
    "      fraction2 = den/len(df)\n",
    "      entropy2 += -fraction2*entropy\n",
    "  return abs(entropy2)\n",
    "\n",
    "#find an attribute that has max ig\n",
    "def find_winner(df):\n",
    "    Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:\n",
    "        #Entropy_att.append(find_entropy_attribute(df,key))\n",
    "        IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)]\n",
    "  \n",
    "#get subtable for a node\n",
    "def get_subtable(df, node,value):\n",
    "  return df[df[node] == value].reset_index(drop=True)\n",
    "\n",
    "# a function for build DT\n",
    "def buildTree(df,tree=None): \n",
    "    Class = df.keys()[-1]   \n",
    "    \n",
    "    \n",
    "\n",
    "    #attribute maximum information gain\n",
    "    node = find_winner(df)\n",
    "    \n",
    "   \n",
    "    attValue = np.unique(df[node])\n",
    "    \n",
    "    #create tree    \n",
    "    if tree is None:                    \n",
    "        tree={}\n",
    "        tree[node] = {}\n",
    "    \n",
    "\n",
    "    for value in attValue:\n",
    "        \n",
    "        subtable = get_subtable(df,node,value)\n",
    "        clValue,counts = np.unique(subtable['Type'],return_counts=True)      \n",
    "\n",
    "        #Checking purity of subset that purity shoould be 0\n",
    "        if len(counts)==1:\n",
    "            tree[node][value] = clValue[0]\n",
    "            \n",
    "        else:        \n",
    "            #Calling the function recursively \n",
    "            tree[node][value] = buildTree(subtable) \n",
    "                   \n",
    "    return tree\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D-Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=buildTree(df)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(inst,tree):\n",
    "    for nodes in tree.keys():\n",
    "        \n",
    "        value=inst[nodes]\n",
    "        \n",
    "        tt=tree[nodes][value]\n",
    "        \n",
    "        prediction=0\n",
    "        \n",
    "        if type(tt) is dict:\n",
    "            prediction = pred(inst,tt)\n",
    "        else:\n",
    "            prediction = tt\n",
    "            break;\n",
    "            \n",
    "    return prediction\n",
    "    \n",
    "\n",
    "import pprint\n",
    "q=df.shape[0]\n",
    "acc=0\n",
    "pp=[]\n",
    "\n",
    "for i in range(q):\n",
    "    ss=df.loc[i, : ]\n",
    "    prediction = pred(ss,t)\n",
    "    if prediction != ['Type']:\n",
    "        acc=acc+1\n",
    "        pp=np.append(pp,i)\n",
    "        \n",
    "pprint.pprint(t)\n",
    "print('Accuracy = ')\n",
    "print(1-(acc/df.shape[0]))\n",
    "print('missclassified data= ')\n",
    "pprint.pprint(pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
